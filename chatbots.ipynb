{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd75630c",
   "metadata": {},
   "source": [
    "# Building A Chatbot\n",
    "\n",
    "In this notebook, we'll go over an example of how to design and implement an LLM-powered chatbot. This chatbot will be able to have a conversation and remember previous interactions.\n",
    "\n",
    "> **Note:** This chatbot that we build will only use the language model to have a conversation. There are several other related concepts that you may be looking for:\n",
    "\n",
    "- **Conversational RAG**: Enable a chatbot experience over an external source of data  \n",
    "- **Agents**: Build a chatbot that can take actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda2e17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OpenAI API and Groq Key and Opensource models\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8d67ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001BBCC300970>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001BBCC301DE0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"gemma2-9b-it\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07cbbc4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Faraz, it's nice to meet you! That's a very impressive title. \\n\\nAs an AI, I'm always interested in learning more about how people are using technology, especially in fields like full stack development. \\n\\nWhat kind of projects are you working on these days?  Do you have a particular area of full stack development that you specialize in?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 26, 'total_tokens': 107, 'completion_time': 0.147272727, 'prompt_time': 0.002132166, 'queue_time': 0.235544774, 'total_time': 0.149404893}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-4e4b8042-0deb-4114-a3a7-5e61c0ed9766-0', usage_metadata={'input_tokens': 26, 'output_tokens': 81, 'total_tokens': 107})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hello,My name is Faraz,and I am an AI Full Stack Developer.\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example of Messages to LLM and whether it remember them-Yes\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(content=\"Hello,My name is Faraz,and I am an AI Full Stack Developer.\"),\n",
    "    AIMessage(content=\"Hello Faraz, it's nice to meet you! That's a very impressive title. \\n\\nAs an AI, I'm always interested in learning more about how people are using technology, especially in fields like full stack development. \\n\\nWhat kind of projects are you working on these days?  Do you have a particular area of full stack development that you specialize in?\"),\n",
    "    HumanMessage(content=\"Hey what's my name and what do I do?\")\n",
    "]\n",
    "\n",
    "response=model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0615df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You said your name is Faraz, and that you are an AI Full Stack Developer.  \\n\\nIs there anything else you'd like to tell me about yourself? ðŸ˜Š  I'm eager to learn more!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 126, 'total_tokens': 173, 'completion_time': 0.085454545, 'prompt_time': 0.006744446, 'queue_time': 0.235993742, 'total_time': 0.092198991}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-abb23ab7-e967-4a02-8b1b-60edb0528ef8-0', usage_metadata={'input_tokens': 126, 'output_tokens': 47, 'total_tokens': 173})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43aafb4",
   "metadata": {},
   "source": [
    "# Message History\n",
    "\n",
    "We can use a Message History class to wrap our model and make it stateful. This will keep track of inputs and outputs of the model, and store them in some datastore. Future interactions will then load those messages and pass them into the chain as part of the input. Letâ€™s see how to use this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"session_id\": \"user_faraz_001\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5781e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, I am Faraz, an AI Software Engineer.\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1631ebd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Faraz, it's great to meet you!  \\n\\nBeing an AI Software Engineer is a fascinating field. What kind of projects are you working on these days?  \\n\\nDo you have any specific questions about AI or anything you'd like to discuss? I'm here to help in any way I can. \\n\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You said your name is Faraz.  \\n\\nIs there anything else I can help you with?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 248, 'total_tokens': 271, 'completion_time': 0.041818182, 'prompt_time': 0.009359292, 'queue_time': 0.019291805000000002, 'total_time': 0.051177474}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-0063e7bb-aea6-47f4-ad5a-74ce66c20db8-0', usage_metadata={'input_tokens': 248, 'output_tokens': 23, 'total_tokens': 271})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking if AI remembers my name\n",
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my Name?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me, I'm happy to learn it! ðŸ˜Š\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Changing config-->session id--> To check if it still remembers\n",
    "config1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Whats my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e143c497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi John! It's nice to meet you.  \\n\\nWhat can I do for you today?\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Re-tell him you name---> now it remembers\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey My name is John\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9fdda3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
